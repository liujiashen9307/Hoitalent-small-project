{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from ggplot import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "df = pd.read_csv('data1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCM Operations Coordinator</td>\n",
       "      <td>1 - 3 Years</td>\n",
       "      <td>For our European Customer Care Center located ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internship| Online Partnership Manager | Head ...</td>\n",
       "      <td>Entry</td>\n",
       "      <td>Are you looking for an internship with possibi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUV Industrial Engineer</td>\n",
       "      <td>3 - 5 Years</td>\n",
       "      <td>Reference RC04506 Do you have a creative way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Android Mobile Developer</td>\n",
       "      <td>3 - 5 Years</td>\n",
       "      <td>Job description  We are the marketing agency f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medior Business Intelligence Developer bij eVi...</td>\n",
       "      <td>3 - 5 Years</td>\n",
       "      <td>As a Business Intelligence Developer within eV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position    Experience  \\\n",
       "0                         SCM Operations Coordinator   1 - 3 Years   \n",
       "1  Internship| Online Partnership Manager | Head ...         Entry   \n",
       "2                            EUV Industrial Engineer   3 - 5 Years   \n",
       "3                    Senior Android Mobile Developer   3 - 5 Years   \n",
       "4  Medior Business Intelligence Developer bij eVi...   3 - 5 Years   \n",
       "\n",
       "                                         Description  \n",
       "0  For our European Customer Care Center located ...  \n",
       "1  Are you looking for an internship with possibi...  \n",
       "2  Reference RC04506 Do you have a creative way o...  \n",
       "3  Job description  We are the marketing agency f...  \n",
       "4  As a Business Intelligence Developer within eV...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy using title only is overall 71%**\n",
    "\n",
    "**Methods of voting classifiers in this attempt as well as the previous one are both not scientific enough. However I do not find a non-tree-based model that can create a good result in this data set yet. It is due to my immature parameter tuning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same step first to ensure the data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['length'] = df['Description'].apply(lambda x: len(str(x).split()))\n",
    "df = df[df['length']>200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then an extra step should be taken for getting rid of the messy character (un-ascii) in Position column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Position']=df['Position'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create cleaned description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_words(content):\n",
    "    letters_only = re.sub(\"[^a-zA-Z-0-9]\", \" \", content) \n",
    "    words = letters_only.lower().split()                             \n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops] \n",
    "    return( \" \".join( meaningful_words ))\n",
    "df['clean']=df['Description'].apply(lambda x:to_words(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small cleansing step will also be taken on the job position , for removing annoying '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Position']=df['Position'].apply(lambda x: re.sub(\"[^a-zA-Z-0-9]\", \" \",x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, data cleansing step is done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same seed can make the results comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train,test = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the position title tends to be short and informative, we can assume that every single word in Job title can be useful for classification. Therefore, the 1-term Bag of word model can be used to extract features from the position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Title = []\n",
    "for each in train['Position']:\n",
    "    Title.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1471, 1397)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer()\n",
    "feature_title = v.fit_transform(Title)\n",
    "print(feature_title.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison with the 1-term BOW for job description, the dimension of feature matrix has a way smaller scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Title = []\n",
    "for each in test['Position']:\n",
    "    Test_Title.append(each)\n",
    "test_feature_title = v.transform(Test_Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarily, tree-based models are fitted on the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1=DecisionTreeClassifier(random_state=999, min_samples_leaf=1)\n",
    "clf2=RandomForestClassifier(n_estimators=1000,random_state=500,n_jobs=-1,min_samples_leaf =1 )\n",
    "clf3=ExtraTreesClassifier(n_estimators=1000,random_state=500,n_jobs=-1,min_samples_leaf =1 )\n",
    "eclf=VotingClassifier(estimators=[('rf', clf2), ('et', clf3)], voting='hard')\n",
    "Classifiers = [clf1,clf2,clf3,eclf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier is 0.6875\n",
      "Accuracy of RandomForestClassifier is 0.709239130435\n",
      "Accuracy of ExtraTreesClassifier is 0.70652173913\n",
      "Accuracy of VotingClassifier is 0.711956521739\n"
     ]
    }
   ],
   "source": [
    "Model = []\n",
    "Accuracy = []\n",
    "for clf in Classifiers:\n",
    "    fit = clf.fit(feature_title ,train['Experience'])\n",
    "    pred = fit.predict(test_feature_title)\n",
    "    Accu = accuracy_score(pred,test['Experience'])\n",
    "    Accuracy.append(Accu)\n",
    "    Model.append(clf.__class__.__name__)\n",
    "    print('Accuracy of '+clf.__class__.__name__+' is '+str(Accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier ensembling random forest and extra tree together produce a result that is better than every single model using job description as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1 - 3 Years</th>\n",
       "      <th>3 - 5 Years</th>\n",
       "      <th>Entry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 - 3 Years</th>\n",
       "      <td>137</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - 5 Years</th>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      1 - 3 Years   3 - 5 Years   Entry\n",
       "Actual                                          \n",
       " 1 - 3 Years           137            44       2\n",
       " 3 - 5 Years            42            72       0\n",
       " Entry                  17             1      53"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['Experience'], pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest discrepency is still between 1-3 year and 3-5 year position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.070830</td>\n",
       "      <td>internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.045480</td>\n",
       "      <td>intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>0.041578</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.014084</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0.013972</td>\n",
       "      <td>wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0.012640</td>\n",
       "      <td>hbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.011284</td>\n",
       "      <td>engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>0.011235</td>\n",
       "      <td>stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.011155</td>\n",
       "      <td>afstudeeropdracht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.010414</td>\n",
       "      <td>informatica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.009507</td>\n",
       "      <td>junior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.008049</td>\n",
       "      <td>graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.007674</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>0.007056</td>\n",
       "      <td>lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.006356</td>\n",
       "      <td>mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.006174</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>0.005642</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>0.005272</td>\n",
       "      <td>specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.005222</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.005215</td>\n",
       "      <td>elektrotechniek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Importance               Word\n",
       "670     0.070830         internship\n",
       "666     0.045480             intern\n",
       "1125    0.041578             senior\n",
       "754     0.014084            manager\n",
       "1378    0.013972                 wo\n",
       "571     0.012640                hbo\n",
       "423     0.011284           engineer\n",
       "1183    0.011235              stage\n",
       "53      0.011155  afstudeeropdracht\n",
       "628     0.010414        informatica\n",
       "700     0.009507             junior\n",
       "553     0.008049           graduate\n",
       "1011    0.007674            project\n",
       "716     0.007056               lead\n",
       "819     0.006356             mobile\n",
       "765     0.006174          marketing\n",
       "1218    0.005642            support\n",
       "1173    0.005272         specialist\n",
       "688     0.005222               java\n",
       "407     0.005215    elektrotechniek"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit = clf2.fit(feature_title,train['Experience'])\n",
    "words = v.get_feature_names()\n",
    "importance = clf2.feature_importances_\n",
    "impordf = pd.DataFrame({'Word' : words, \n",
    "                        'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My data set is not large enough, so the position from 'Thales' may somehow produce biased result as this company consistently recruit intern/junior level staff. Once the data set is large enough, such problem may vanish.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on both position and job description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if I combine the features from job description and those from job title together, what will happen? **In order to find out something more interesting, I want to give an attempt on ensembling model using the probability-result of description-model and the job title features as the combined features and make the new prediction. I am very much not sure about the performance of this model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_desc = []\n",
    "for each in train['clean']:\n",
    "    train_desc.append(each)\n",
    "\n",
    "c = CountVectorizer()\n",
    "feature_1 = c.fit_transform(train_desc)\n",
    "\n",
    "test_desc = []\n",
    "for each in test['clean']:\n",
    "    test_desc.append(each)\n",
    "test_features_1 = c.transform(test_desc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf =RandomForestClassifier(n_estimators=200,random_state=999,n_jobs=-1,min_samples_leaf =1 )\n",
    "fit = clf.fit(feature_1,train['Experience'])\n",
    "pred_o = fit.predict_proba(test_features_1)\n",
    "pred_i = fit.predict_proba(feature_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create new array as the new feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_t = feature_title.toarray()\n",
    "test_feature_t = test_feature_title.toarray()\n",
    "New_features = np.concatenate((feature_t,pred_i),axis=1)\n",
    "New_test_features = np.concatenate((test_feature_t,pred_o),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I worry about is the potential overfitting problem. I will try to spend more time on parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1_2=DecisionTreeClassifier(random_state=999, min_samples_leaf=1)\n",
    "clf2_2=RandomForestClassifier(n_estimators=1000,random_state=99,n_jobs=-1,min_samples_leaf =1,max_features='log2' )\n",
    "clf3_2=ExtraTreesClassifier(n_estimators=1000,random_state=99,n_jobs=-1,min_samples_leaf =1,max_features='log2' )\n",
    "eclf_2=VotingClassifier(estimators=[('rf', clf2_2), ('et', clf3_2)], voting='soft',weights=[1,1.1])\n",
    "Classifiers_2 = [clf1_2,clf2_2,clf3_2,eclf_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier is 0.682065217391\n",
      "Accuracy of RandomForestClassifier is 0.703804347826\n",
      "Accuracy of ExtraTreesClassifier is 0.717391304348\n",
      "Accuracy of VotingClassifier is 0.711956521739\n"
     ]
    }
   ],
   "source": [
    "Model_2 = []\n",
    "Accuracy_2 = []\n",
    "for clf_ in Classifiers_2:\n",
    "    fit = clf_.fit(New_features ,train['Experience'])\n",
    "    pred = fit.predict(New_test_features)\n",
    "    Accu = accuracy_score(pred,test['Experience'])\n",
    "    Accuracy_2.append(Accu)\n",
    "    Model_2.append(clf_.__class__.__name__)\n",
    "    print('Accuracy of '+clf_.__class__.__name__+' is '+str(Accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the overall performance of new model does not increase a lot in comparison with the model built by job title only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several brief conclusions can be made below:\n",
    "\n",
    "a. Job title is short, but obviously more informative. Also, the integrity of data will be better with job title as feature source.\n",
    "\n",
    "b. About ensemble models: typically it should use relatively different models (such as Logistic Regression and Tree model) rather than close models to ensemble models. However, since I have tested several other models like LR, SVC and NB, none of them will provide a satisfying  result, I just use tree based model only. However, I do believe that with a fine parameter tunning technique, good result can be obtained from non-tree-based model also."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
